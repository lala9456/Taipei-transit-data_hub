{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2.service_account import Credentials\n",
    "import geopy.distance\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIGQUERY_CREDENTIALS_FILE_PATH = r\"D:\\data_engineer\\dev_TIR_group2\\Taipei-transit-data_hub\\airflow\\dags\\harry_GCS_BigQuery_write_cred.json\"\n",
    "BIGQUERY_CREDENTIALS_FILE_PATH = r\"C:\\dev_TIR101\\Taipei-transit-data_hub\\airflow\\dags\\harry_GCS_BigQuery_write_cred.json\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = BIGQUERY_CREDENTIALS_FILE_PATH\n",
    "BQ_CLIENT = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrt_sql_query=\"\"\"  \n",
    "    SELECT mrt_station_id,lat,lng\n",
    "    FROM `MRT_GCS_to_BQ_SRC_ODS_DIM.DIM_MRT_static_data`\n",
    "\"\"\"\n",
    "bus_sql_query=\"\"\"  \n",
    "    SELECT  bus_station_id,lat,lng\n",
    "    FROM `BUS_GCS_to_BQ_SRC_ODS_DIM.DIM_Bus_static_data`\n",
    "\"\"\"\n",
    "bike_sql_query=\"\"\"  \n",
    "    SELECT  bike_station_id,lat,lng \n",
    "    FROM `ETL_DIM.DIM_bike_station`\n",
    "\"\"\"\n",
    "\n",
    "def query_bq_to_df(client: bigquery.Client,sql_query:str) -> pd.DataFrame:\n",
    "    try:\n",
    "        query_job = client.query(sql_query)\n",
    "        return query_job.to_dataframe()  # Convert result to DataFrame\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to query bigquery table, reason: {e}\")\n",
    "mrt_df = query_bq_to_df(client=BQ_CLIENT,sql_query=mrt_sql_query)\n",
    "bus_df = query_bq_to_df(client=BQ_CLIENT,sql_query=bus_sql_query)\n",
    "youbike_df = query_bq_to_df(client=BQ_CLIENT,sql_query=bike_sql_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       11.879406\n",
       "1       11.560791\n",
       "2       12.168026\n",
       "3       11.792979\n",
       "4       11.522385\n",
       "          ...    \n",
       "1410    15.126657\n",
       "1411    15.483675\n",
       "1412    15.424026\n",
       "1413    15.177171\n",
       "1414    15.289883\n",
       "Length: 1415, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_dis(df,location2):\n",
    "    location1 = (df[\"lat\"],df[\"lng\"])\n",
    "    return(geopy.distance.geodesic(location1, location2).kilometers)\n",
    "\n",
    "youbike_df.apply(lambda df :calculate_dis(df,location2=(25.136900,121.459550)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "youbike_df['district'] = youbike_df['district'].replace('臺大公館校區','大安區')\n",
    "youbike_df['city_code']='TPE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 99/121 [00:37<00:09,  2.31it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 83%|████████▎ | 100/121 [00:37<00:09,  2.16it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 83%|████████▎ | 101/121 [00:38<00:09,  2.18it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 84%|████████▍ | 102/121 [00:38<00:08,  2.23it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 85%|████████▌ | 103/121 [00:39<00:07,  2.26it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 86%|████████▌ | 104/121 [00:39<00:07,  2.31it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 87%|████████▋ | 105/121 [00:40<00:07,  2.26it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 88%|████████▊ | 106/121 [00:40<00:06,  2.27it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 88%|████████▊ | 107/121 [00:40<00:06,  2.31it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 89%|████████▉ | 108/121 [00:41<00:05,  2.36it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 90%|█████████ | 109/121 [00:41<00:05,  2.36it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 91%|█████████ | 110/121 [00:42<00:04,  2.36it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 92%|█████████▏| 111/121 [00:42<00:04,  2.36it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 93%|█████████▎| 112/121 [00:43<00:03,  2.35it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 93%|█████████▎| 113/121 [00:43<00:03,  2.36it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 94%|█████████▍| 114/121 [00:43<00:02,  2.38it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 95%|█████████▌| 115/121 [00:44<00:02,  2.34it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 96%|█████████▌| 116/121 [00:44<00:02,  2.26it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 97%|█████████▋| 117/121 [00:45<00:01,  2.25it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 98%|█████████▊| 118/121 [00:45<00:01,  2.25it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 98%|█████████▊| 119/121 [00:46<00:00,  2.22it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      " 99%|█████████▉| 120/121 [00:46<00:00,  2.09it/s]C:\\Users\\T14 Gen 3\\AppData\\Local\\Temp\\ipykernel_19016\\83382247.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)\n",
      "100%|██████████| 121/121 [00:47<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(mrt_df))):\n",
    "    mrt_station_id = mrt_df.loc[i,\"mrt_station_id\"]\n",
    "    location_mrt = (mrt_df.loc[i,\"lat\"] , mrt_df.loc[i,\"lng\"])\n",
    "    youbike_df[mrt_station_id]= youbike_df.apply(lambda df :calculate_dis(df,location_mrt),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_youbike = youbike_df.melt(id_vars=[\"bike_station_id\",\t\"lat\",\"lng\"],var_name=\"mrt_station_id\",value_name=\"distance\" )\n",
    "fact_youbike = fact_youbike.loc[:,[\"bike_station_id\",\"mrt_station_id\",\"distance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bike_station_id</th>\n",
       "      <th>mrt_station_id</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500107102</td>\n",
       "      <td>O02</td>\n",
       "      <td>6.986596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500107099</td>\n",
       "      <td>O02</td>\n",
       "      <td>7.208812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500107065</td>\n",
       "      <td>O02</td>\n",
       "      <td>6.809924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500107086</td>\n",
       "      <td>O02</td>\n",
       "      <td>11.338723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500107045</td>\n",
       "      <td>O02</td>\n",
       "      <td>6.757624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171210</th>\n",
       "      <td>500119045</td>\n",
       "      <td>O54</td>\n",
       "      <td>10.703496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171211</th>\n",
       "      <td>500119070</td>\n",
       "      <td>O54</td>\n",
       "      <td>11.054859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171212</th>\n",
       "      <td>500119048</td>\n",
       "      <td>O54</td>\n",
       "      <td>10.971054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171213</th>\n",
       "      <td>500119077</td>\n",
       "      <td>O54</td>\n",
       "      <td>10.791606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171214</th>\n",
       "      <td>500119049</td>\n",
       "      <td>O54</td>\n",
       "      <td>10.959046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171215 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bike_station_id mrt_station_id   distance\n",
       "0             500107102            O02   6.986596\n",
       "1             500107099            O02   7.208812\n",
       "2             500107065            O02   6.809924\n",
       "3             500107086            O02  11.338723\n",
       "4             500107045            O02   6.757624\n",
       "...                 ...            ...        ...\n",
       "171210        500119045            O54  10.703496\n",
       "171211        500119070            O54  11.054859\n",
       "171212        500119048            O54  10.971054\n",
       "171213        500119077            O54  10.791606\n",
       "171214        500119049            O54  10.959046\n",
       "\n",
       "[171215 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_youbike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7572683270119502"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location1 = (25.0330, 121.5654)  # 台北 101 的經緯度\n",
    "location2 = (25.0478, 121.5319)  # 台北車站的經緯度\n",
    "\n",
    "# 計算地理距離\n",
    "distance = geopy.distance.geodesic(location1, location2).kilometers\n",
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bike_mrt_distance_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 99/121 [00:37<00:10,  2.10it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 83%|████████▎ | 100/121 [00:38<00:09,  2.16it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 83%|████████▎ | 101/121 [00:38<00:09,  2.16it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 84%|████████▍ | 102/121 [00:39<00:09,  2.01it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 85%|████████▌ | 103/121 [00:39<00:08,  2.03it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 86%|████████▌ | 104/121 [00:40<00:08,  2.01it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 87%|████████▋ | 105/121 [00:40<00:07,  2.05it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 88%|████████▊ | 106/121 [00:41<00:07,  2.06it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 88%|████████▊ | 107/121 [00:41<00:06,  2.13it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 89%|████████▉ | 108/121 [00:42<00:06,  2.11it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 90%|█████████ | 109/121 [00:42<00:05,  2.14it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 91%|█████████ | 110/121 [00:43<00:05,  2.17it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 92%|█████████▏| 111/121 [00:43<00:04,  2.15it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 93%|█████████▎| 112/121 [00:44<00:04,  2.11it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 93%|█████████▎| 113/121 [00:44<00:03,  2.08it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 94%|█████████▍| 114/121 [00:45<00:03,  2.02it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 95%|█████████▌| 115/121 [00:45<00:02,  2.02it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 96%|█████████▌| 116/121 [00:46<00:02,  1.96it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 97%|█████████▋| 117/121 [00:46<00:02,  1.90it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 98%|█████████▊| 118/121 [00:47<00:01,  1.81it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 98%|█████████▊| 119/121 [00:47<00:01,  1.81it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      " 99%|█████████▉| 120/121 [00:48<00:00,  1.87it/s]c:\\dev_TIR101\\Taipei-transit-data_hub\\local_dev_temp\\andy\\bike\\bike_mrt_distance_pipeline.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  youbike_df[mrt_station_id] = youbike_df.apply(\n",
      "100%|██████████| 121/121 [00:48<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# BIGQUERY_CREDENTIALS_FILE_PATH = r\"D:\\data_engineer\\dev_TIR_group2\\Taipei-transit-data_hub\\airflow\\dags\\harry_GCS_BigQuery_write_cred.json\"\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = BIGQUERY_CREDENTIALS_FILE_PATH\n",
    "# BQ_CLIENT = bigquery.Client()\n",
    "from bike_mrt_distance_pipeline import *\n",
    "mrt_df = get_mrt_df(client=BQ_CLIENT)\n",
    "youbike_df = get_youbike_df(client=BQ_CLIENT)\n",
    "youbike_mrt_distance = create_bike_mrt_distance(\n",
    "    mrt_df=mrt_df, youbike_df=youbike_df)\n",
    "youbike_mrt_distance.to_csv(\n",
    "    \"youbike_mrt_distance.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# bus_df = get_bus_df(client=BQ_CLIENT)\n",
    "# youbike_bus_distance = create_bike_bus_distance(\n",
    "#     youbike_df=youbike_df, bus_df=bus_df)\n",
    "# youbike_bus_distance.to_csv(\n",
    "#     \"youbike_bus_distance.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_df_to_bq(\n",
    "    client: bigquery.Client,\n",
    "    df: pd.DataFrame,\n",
    "    dataset_name: str,\n",
    "    table_name: str,\n",
    "    schema,\n",
    "    filetype: str = \"parquet\",\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Upload a pandas dataframe to bigquery.\n",
    "\n",
    "    Args:\n",
    "        client (bigquery.Client): The client to use to upload to bigquery.\n",
    "        df (pd.DataFrame): The dataframe to upload.\n",
    "        dataset_name (str): The name of the dataset to upload to.\n",
    "        table_name (str): The name of the table to upload to.\n",
    "        schema (List[bigquery.SchemaField], optional): The schema of the table to upload to. Default is None.\n",
    "                                                        If None, use the default schema (automatic-detect).\n",
    "        filetype (str): The type of the file to download. Default is \"parquet\". Can be \"parquet\" or \"csv\" or \"jsonl\".\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the upload was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    dataset_id = client.dataset(dataset_name)\n",
    "    table_id = dataset_id.table(table_name)\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "    )\n",
    "    if filetype == \"parquet\":\n",
    "        job_config.source_format = bigquery.SourceFormat.PARQUET\n",
    "    elif filetype == \"csv\":\n",
    "        job_config.source_format = bigquery.SourceFormat.CSV\n",
    "    elif filetype == \"jsonl\":\n",
    "        job_config.source_format = bigquery.SourceFormat.JSONL\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Invalid filetype: {filetype}. Please specify 'parquet' or 'csv' or 'jsonl'.\"\n",
    "        )\n",
    "    if schema:\n",
    "        job_config.schema = schema\n",
    "\n",
    "    try:\n",
    "        job = client.load_table_from_dataframe(\n",
    "            df, table_id, job_config=job_config)\n",
    "        job.result()  # Wait for the job to complete\n",
    "        table = client.get_table(table_id)\n",
    "        print(f\"Table {table.table_id} created with {table.num_rows} rows.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to upload df to bigquery, reason: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bike_station_id      Int64\n",
       "mrt_station_id      object\n",
       "distance           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youbike_mrt_distance.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table DIM_youbike_mrt_distance created with 171215 rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youbike_mrt_distance_schema = [\n",
    "    bigquery.SchemaField(\"bike_station_id\", \"INT64\"),\n",
    "    bigquery.SchemaField(\"mrt_station_id\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"distance\", \"FLOAT\")\n",
    "]\n",
    "upload_df_to_bq(client=BQ_CLIENT,\n",
    "    df=youbike_mrt_distance,\n",
    "    dataset_name = \"ETL_DIM\",\n",
    "    table_name = \"DIM_youbike_mrt_distance\",\n",
    "    schema =youbike_mrt_distance_schema ,\n",
    "    filetype= \"csv\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youbike_bus_distance_schema = [\n",
    "    bigquery.SchemaField(\"bike_station_id\", \"INT64\"),\n",
    "    bigquery.SchemaField(\"bus_station_id\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"distance\", \"FLOAT\")\n",
    "]\n",
    "upload_df_to_bq(client=BQ_CLIENT,\n",
    "    df=youbike_mrt_distance,\n",
    "    dataset_name = \"ETL_FACT\",\n",
    "    table_name = \"FACT_youbike_bus_distance\",\n",
    "    schema =youbike_bus_distance_schema ,\n",
    "    filetype= \"csv\",)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_BQ(client:bigquery.Client):\n",
    "    query = client.query(\n",
    "        \"\"\"\n",
    "        SELECT * FROM `ETL_FACT.FACT_bike_realtime`\n",
    "        ORDER BY `source_time` DESC\n",
    "        LIMIT 1000\n",
    "        \"\"\"\n",
    "    )\n",
    "    df = query.to_dataframe()\n",
    "    return(df)\n",
    "df = get_data_from_BQ(client=BQ_CLIENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bike_station_id</th>\n",
       "      <th>aval_bike</th>\n",
       "      <th>aval_space</th>\n",
       "      <th>create_time</th>\n",
       "      <th>source_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500111023</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-05-17 00:05:54.701103+00:00</td>\n",
       "      <td>2024-05-16 23:58:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500110040</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-05-17 00:05:54.701103+00:00</td>\n",
       "      <td>2024-05-16 23:58:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500113087</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-05-17 00:05:54.701103+00:00</td>\n",
       "      <td>2024-05-16 23:58:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500108006</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-05-17 00:05:54.701103+00:00</td>\n",
       "      <td>2024-05-16 23:58:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500104023</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>2024-05-17 00:05:54.701103+00:00</td>\n",
       "      <td>2024-05-16 23:58:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>500108030</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-05-17 00:05:54.701103+00:00</td>\n",
       "      <td>2024-05-16 23:58:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>500106008</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2024-05-17 00:05:54.701103+00:00</td>\n",
       "      <td>2024-05-16 23:58:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>500107020</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-05-17 00:05:54.701103+00:00</td>\n",
       "      <td>2024-05-16 23:58:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>500103054</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-05-17 00:05:54.701103+00:00</td>\n",
       "      <td>2024-05-16 23:58:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>500107053</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-05-17 00:05:54.701103+00:00</td>\n",
       "      <td>2024-05-16 23:58:23+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bike_station_id  aval_bike  aval_space                      create_time  \\\n",
       "0          500111023         40           8 2024-05-17 00:05:54.701103+00:00   \n",
       "1          500110040         22           8 2024-05-17 00:05:54.701103+00:00   \n",
       "2          500113087         12           8 2024-05-17 00:05:54.701103+00:00   \n",
       "3          500108006         10           1 2024-05-17 00:05:54.701103+00:00   \n",
       "4          500104023         23           9 2024-05-17 00:05:54.701103+00:00   \n",
       "..               ...        ...         ...                              ...   \n",
       "995        500108030          9           4 2024-05-17 00:05:54.701103+00:00   \n",
       "996        500106008          4          11 2024-05-17 00:05:54.701103+00:00   \n",
       "997        500107020         25           7 2024-05-17 00:05:54.701103+00:00   \n",
       "998        500103054         10           5 2024-05-17 00:05:54.701103+00:00   \n",
       "999        500107053          9           3 2024-05-17 00:05:54.701103+00:00   \n",
       "\n",
       "                  source_time  \n",
       "0   2024-05-16 23:58:23+00:00  \n",
       "1   2024-05-16 23:58:23+00:00  \n",
       "2   2024-05-16 23:58:23+00:00  \n",
       "3   2024-05-16 23:58:23+00:00  \n",
       "4   2024-05-16 23:58:23+00:00  \n",
       "..                        ...  \n",
       "995 2024-05-16 23:58:23+00:00  \n",
       "996 2024-05-16 23:58:23+00:00  \n",
       "997 2024-05-16 23:58:23+00:00  \n",
       "998 2024-05-16 23:58:23+00:00  \n",
       "999 2024-05-16 23:58:23+00:00  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
